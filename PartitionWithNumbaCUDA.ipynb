{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/trefftzc/partition/blob/main/PartitionWithNumbaCUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code to solve the partition problem using an NVIDIA GPU\n",
        "The code below solves the partition problem. This code is written in Python and it uses NUMBA to generate code that executes on an NVIDIA GPU. Make sure that in the Notebook setting you choose a GPU as accelerator."
      ],
      "metadata": {
        "id": "dyt-RUd8Qojc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ-AogZUQFt1",
        "outputId": "f0b3fb3e-5bfb-47bb-b1e3-e8d77dcecb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The value of n is \n",
            " 24\n",
            "The values in the multiset are: \n",
            "\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 \n",
            "The number of possible partitions is:  8388608\n",
            "Execution time with Grid Block:  0.23495078086853027\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum:  23\n",
            "Second partition: \n",
            "23  sum:  23\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 64 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum:  23\n",
            "Second partition: \n",
            "23  sum:  23\n",
            "\n",
            "Execution time with parallelFor:  0.6948294639587402\n",
            "The value of n is \n",
            " 24\n",
            "The values in the multiset are: \n",
            "\n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 23 \n",
            "The number of possible partitions is:  8388608\n",
            "Execution time with Grid Block:  0.10473251342773438\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum:  23\n",
            "Second partition: \n",
            "23  sum:  23\n",
            "\n",
            "Solution:\n",
            "\n",
            "First partition: \n",
            "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1  sum:  23\n",
            "Second partition: \n",
            "23  sum:  23\n",
            "\n",
            "Execution time with parallelFor:  0.041609764099121094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: Grid size 1 will likely result in GPU under-utilization due to low occupancy.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# Program that solves the partition problem in python\n",
        "# Parallel version with numba\n",
        "#\n",
        "import sys\n",
        "import numpy as np\n",
        "#import numba\n",
        "from numba import cuda\n",
        "from numba.cuda.cudadrv.devicearray import DeviceNDArray\n",
        "import time\n",
        "\n",
        "# This is a max reduction\n",
        "# The documentation is available here:\n",
        "# https://numba.readthedocs.io/en/stable/cuda/reduction.html\n",
        "@cuda.reduce\n",
        "def max_reduce(a, b):\n",
        "  if a > b:\n",
        "    return a\n",
        "  else:\n",
        "    return b\n",
        "\n",
        "\n",
        "#\n",
        "# This is the kernel, the code that is executed in each processor\n",
        "# in the GPU\n",
        "#\n",
        "@cuda.jit\n",
        "def evaluatePartition(  array:DeviceNDArray,result:DeviceNDArray,n:np.dtype=np.int64):\n",
        "   value = cuda.grid(1)\n",
        "   sum0s = 0\n",
        "   sum1s = 0\n",
        "   mask = 1\n",
        "   for i in range(0,n):\n",
        "    if ((mask & value) != 0):\n",
        "      sum1s = sum1s + array[i]\n",
        "    else:\n",
        "      sum0s = sum0s + array[i]\n",
        "    mask = mask * 2\n",
        "   if (sum0s == sum1s):\n",
        "     # print(\"Evaluate partition \",value,\" returns \",value)\n",
        "     result[value] = value\n",
        "   else:\n",
        "    # print(\"Evaluate partition \",value,\" returns \",0)\n",
        "    result[value] = 0\n",
        "\n",
        "def printResults(value, n, array):\n",
        "  print(\"Solution:\\n\")\n",
        "  print(\"First partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "\n",
        "    if ((mask & value) != 0):\n",
        "      print(array[i],end=\" \")\n",
        "      sum = sum + array[i]\n",
        "    mask = mask * 2\n",
        "\n",
        "  print(\" sum: \",sum)\n",
        "  print(\"Second partition: \")\n",
        "  mask = 1\n",
        "  sum = 0\n",
        "  for i in range(0,n):\n",
        "    if ((mask & value) == 0):\n",
        "      print(array[i],end=\" \")\n",
        "      sum = sum + array[i]\n",
        "\n",
        "    mask = mask * 2\n",
        "\n",
        "  print(\" sum: \",sum)\n",
        "  print()\n",
        "\n",
        "def parallelFor(n,array,nPartitions):\n",
        "  solutionFound = 0\n",
        "  solution = -1\n",
        "  result = np.zeros(nPartitions,dtype=np.int64)\n",
        "  arrayGPU = cuda.to_device(array)\n",
        "  resultGPU = cuda.to_device(result)\n",
        "  evaluatePartition.forall(nPartitions)( arrayGPU,resultGPU, n)\n",
        "  # Copy the result array back to the CPU\n",
        "  # resultGPU.copy_to_host(result)\n",
        "\n",
        "  # print(\"At the end array contains: \",result)\n",
        "  # solutionFound = np.max(result)\n",
        "  solutionFound = max_reduce(resultGPU)\n",
        "  solution = solutionFound\n",
        "\n",
        "\n",
        "  if (solutionFound):\n",
        "    printResults(solution, n, array)\n",
        "  else:\n",
        "    print(\"No solution was found.\")\n",
        "\n",
        "def main():\n",
        "\n",
        "  # n is the size of the array with the integer values\n",
        "  # array contains the set of integer values\n",
        "  # n is the size of the array with the integer values\n",
        "  # array contains the set of integer values\n",
        "\n",
        "  n = 24\n",
        "\n",
        "  print(\"The value of n is \\n\",n)\n",
        "  array=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,23]\n",
        "\n",
        "\n",
        "  print(\"The values in the multiset are: \\n\")\n",
        "  for i in range(0,n):\n",
        "    print(array[i],end=\" \")\n",
        "\n",
        "  print(\"\")\n",
        "\n",
        "  nPartitions = 1\n",
        "  # Only half of all possible partitions need be examined\n",
        "  # The second half is symmetrical to the first half\n",
        "  for i in range(1,n):\n",
        "    nPartitions = nPartitions * 2\n",
        "\n",
        "  print(\"The number of possible partitions is: \",nPartitions)\n",
        "  solutionFound = 0\n",
        "  solution = -1\n",
        "  result = np.zeros(nPartitions,dtype=np.int64)\n",
        "  threadsPerBlock = 0\n",
        "  blocksPerGrid = 0\n",
        "  if nPartitions >= 512:\n",
        "    threadsPerBlock = 512\n",
        "    blocksPerGrid = nPartitions // 512\n",
        "  else:\n",
        "    threadsPerBlock = 32\n",
        "    blocksPerGrid = nPartitions // 32\n",
        "  #for i in prange(1,nPartitions):\n",
        "  # for i in range(1,nPartitions):\n",
        "  start = time.time()\n",
        "  arrayGPU = cuda.to_device(array)\n",
        "  resultGPU = cuda.to_device(result)\n",
        "  evaluatePartition[blocksPerGrid,threadsPerBlock]( arrayGPU,resultGPU, n)\n",
        "  # Copy the result array back to the CPU\n",
        "  resultGPU.copy_to_host(result)\n",
        "  end = time.time()\n",
        "  print(\"Execution time with Grid Block: \",end-start)\n",
        "  # print(\"At the end array contains: \",result)\n",
        "  solutionFound = np.max(result)\n",
        "  solution = solutionFound\n",
        "\n",
        "\n",
        "  if (solutionFound):\n",
        "    printResults(solution, n, array)\n",
        "  else:\n",
        "    print(\"No solution was found.\")\n",
        "\n",
        "# An alternative way, using the forAll function\n",
        "  start = time.time()\n",
        "  parallelFor(n,array,nPartitions)\n",
        "  end = time.time()\n",
        "  print(\"Execution time with parallelFor: \",end-start)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "# Call twice so that the compilation time is not counted\n",
        "  main()\n",
        "  main()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8eis5ZUCPN4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}